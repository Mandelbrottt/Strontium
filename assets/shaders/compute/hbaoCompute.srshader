#type compute
#version 440
/*
 * A compute shader to compute screenspace horizon-based AO. Based off of the sample
 * implementation provided by NVIDIA:
 * https://github.com/nvpro-samples/gl_ssao/blob/master/hbao.frag.glsl
 * Effect is computed at quarter resolution.
*/

#define PI 3.141592654

#define NUM_STEPS 4
#define NUM_DIRECTIONS 8
#define BIAS 1e-6

layout(local_size_x = 8, local_size_y = 8) in;

// The output texture for the AO.
layout(rg16f, binding = 0) restrict writeonly uniform image2D aoOut;

layout(binding = 3) uniform sampler2D gDepth;
layout(binding = 4) uniform sampler2D gNormal;

// Camera specific uniforms.
layout(std140, binding = 0) uniform CameraBlock
{
  mat4 u_viewMatrix;
  mat4 u_projMatrix;
  mat4 u_invViewProjMatrix;
  vec3 u_camPosition;
  vec4 u_nearFar; // Near plane (x), far plane (y). z and w are unused.
};

layout(std140, binding = 1) uniform AOBlock
{
  vec4 u_aoParams1; // World-space radius (x), ao multiplier (y), ao exponent (z).
};

float computeHBAO(ivec2 coords, vec2 uv, vec4 aoParams, sampler2D depthTex,
                  sampler2D normalTex, mat4 view, mat4 invVP, vec2 fullResTexel);

// https://stackoverflow.com/questions/51108596/linearize-depth
float linearizeDepth(float d, float zNear, float zFar)
{
  float zN = 2.0 * d - 1.0;
  return 2.0 * zNear * zFar / (zFar + zNear - zN * (zFar - zNear));
}

// Fast octahedron normal vector decoding.
// https://jcgt.org/published/0003/02/01/
vec2 signNotZero(vec2 v)
{
  return vec2((v.x >= 0.0) ? 1.0 : -1.0, (v.y >= 0.0) ? 1.0 : -1.0);
}
vec3 decodeNormal(vec2 texCoords, sampler2D encodedNormals)
{
  vec2 e = texture(encodedNormals, texCoords).xy;
  vec3 v = vec3(e.xy, 1.0 - abs(e.x) - abs(e.y));
  if (v.z < 0)
    v.xy = (1.0 - abs(v.yx)) * signNotZero(v.xy);
  return normalize(v);
}

void main()
{
  ivec2 invoke = ivec2(gl_GlobalInvocationID.xy);

  // Quarter resolution.
  ivec2 gBufferCoords = 4 * invoke;
  vec2 texelSize = vec2(1.0) / vec2(textureSize(gDepth, 0).xy);
  vec2 gBufferUV = (vec2(gBufferCoords) + 0.5.xx) * texelSize;

  float linearDepth = linearizeDepth(textureLod(gDepth, gBufferUV, 2.0).r, u_nearFar.x, u_nearFar.y);

  float ao = computeHBAO(invoke, gBufferUV, u_aoParams1, gDepth, gNormal,
                         u_viewMatrix, u_invViewProjMatrix, texelSize);

  imageStore(aoOut, invoke, vec4(pow(ao, u_aoParams1.z), linearDepth, 1.0, 1.0));
}

// Sample a dithering pattern.
float sampleDither(ivec2 coords)
{
  const mat4 ditherMatrix = mat4
  (
    vec4(0.0, 0.5, 0.125, 0.625),
    vec4(0.75, 0.22, 0.875, 0.375),
    vec4(0.1875, 0.6875, 0.0625, 0.5625),
    vec4(0.9375, 0.4375, 0.8125, 0.3125)
  );

  return ditherMatrix[coords.x % 4][coords.y % 4];
}

// Create a rotation matrix with the dithering function above.
mat2 randomRotation(ivec2 coords)
{
  float theta = 2.0 * PI * sampleDither(coords);
  float sinTheta = sin(theta);
  float cosTheta = cos(theta);
  return mat2(cosTheta, sinTheta, -sinTheta, cosTheta);
}

mat2 rotation(float theta)
{
  float sinTheta = sin(theta);
  float cosTheta = cos(theta);
  return mat2(cosTheta, sinTheta, -sinTheta, cosTheta);
}

// HBAO falloff.
float falloff(float distanceSquare, float invR2)
{
  return distanceSquare * invR2 + 1.0;
}

// Decodes the worldspace position of the fragment from depth.
vec3 decodePosition(vec2 texCoords, sampler2D depthMap, mat4 invVP)
{
  float depth = texture(depthMap, texCoords, 2.0).r;
  vec3 clipCoords = 2.0 * vec3(texCoords, depth) - 1.0.xxx;
  vec4 temp = invVP * vec4(clipCoords, 1.0);
  return temp.xyz / temp.w;
}

//------------------------------------------------------------------------------
// P = view-space position at the kernel center.
// N = view-space normal at the kernel center.
// S = view-space position of the current sample.
//------------------------------------------------------------------------------
float computeAO(vec3 p, vec3 n, vec3 s, float invR2)
{
  vec3 v = s - p;
  float vDotV = max(dot(v, v), 1e-4);
  float nDotV = dot(n, v) * 1.0 / sqrt(vDotV);

  return clamp(nDotV - BIAS, 0.0, 1.0) * clamp(falloff(vDotV, invR2), 0.0, 1.0);
}

float
computeHBAO(ivec2 coords, vec2 uv, vec4 aoParams, sampler2D depthTex,
            sampler2D normalTex, mat4 view, mat4 invVP, vec2 fullResTexel)
{
  // Compute the view-space position and normal.
  vec3 viewPos = (view * vec4(decodePosition(uv, depthTex, invVP), 1.0)).xyz;
  vec3 viewNormal = normalize((view * vec4(decodeNormal(uv, normalTex), 0.0)).xyz);

  // Screen-space radius of the sample disk.
  float sRadius = aoParams.x / max(viewPos.z, 1e-4);

  const float stepSize = sRadius / (float(NUM_STEPS) + 1.0);
  const float alpha = 2.0 * PI / float(NUM_DIRECTIONS);

  // Gather AO within the sample disk.
  float ao = 0.0;
  // Outer loop rotates about the sample point.
  for (int i = 0; i < NUM_DIRECTIONS; i++)
  {
    // Compute a jittered direction vector.
    float theta = alpha * float(i);
    vec2 direction = rotation(theta) * randomRotation(coords) * vec2(1.0, 0.0);

    // Compute a jittered starting position.
    float ray = (sampleDither(coords) * stepSize) + 1.0;

    // Inner loop raymarches through the depth buffer gathering AO contributions.
    for (uint j = 0; j < NUM_STEPS; j++)
    {
      vec2 snappedUV = round(ray * direction) * fullResTexel + uv;
      vec3 samplePos = (view * vec4(decodePosition(snappedUV, depthTex, invVP), 1.0)).xyz;

      ray += stepSize;

      ao += computeAO(viewPos, viewNormal, samplePos, aoParams.x);
    }
  }

  ao *= aoParams.y / (float(NUM_STEPS) * float(NUM_DIRECTIONS));

  return clamp(1.0 - 2.0 * ao, 0.0, 1.0);
}
